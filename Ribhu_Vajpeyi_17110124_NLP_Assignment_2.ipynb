{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ribhu_Vajpeyi_17110124_NLP_Assignment_2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1OL2MjxSrLT",
        "colab_type": "text"
      },
      "source": [
        "Note: This python notebook requires the latest version of nltk (3.4.5). Kindly ensure only the latest version is imported"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooCe4eS1ptQa",
        "colab_type": "code",
        "outputId": "1f2f24ec-c32f-4cb4-e52a-10a95f057c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!pip3 install nltk==3.4.5\n",
        "\n",
        "import re\n",
        "import io\n",
        "import numpy as np\n",
        "import nltk\n",
        "import math\n",
        "from urllib import request\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.6/dist-packages (3.4.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4.5) (1.12.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s2vMDkCP9Ys",
        "colab_type": "text"
      },
      "source": [
        "##Getting Data from Project Gutengerg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1aXXX16vLE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"http://www.gutenberg.org/files/31100/31100.txt\"\n",
        "response = request.urlopen(url)\n",
        "dataset = response.read().decode('utf8', 'replace')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lCwkCHjQINO",
        "colab_type": "text"
      },
      "source": [
        "##Sentence and Word Tokeniser\n",
        "\n",
        "Note: 'train' and 'test' is refreshed and earsed everytime it is used in a computation. Thias is a bug in the latest nltk version (3.4.5) which has not been fixed. Hence before using the following blocks, re-run this block to re-initialise 'train' and 'test' - MLEdist_unigram block, MLEdist_bigram block, MLEdist_trigram block, MLEdist_quadgram block and perplexity() function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWvcsUOQMkuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_tokenize_list = nltk.tokenize.sent_tokenize(dataset[1291:])\n",
        "for sent in sent_tokenize_list:\n",
        "  sent_tokenize_list[sent_tokenize_list.index(sent)] = nltk.lm.preprocessing.pad_both_ends(list(nltk.tokenize.word_tokenize(re.sub(r'[^\\w\\s]\\s|\"\\n\"',' ',sent[0:len(sent)-1]))), n=2)\n",
        "\n",
        "train = sent_tokenize_list[0:round( len(sent_tokenize_list)*0.8 )]\n",
        "test = sent_tokenize_list[round( len(sent_tokenize_list)*0.8 ):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqLishXRRKF6",
        "colab_type": "text"
      },
      "source": [
        "##MLEdist_unigram Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXY9kRPyCMLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2baf8d3-2a99-4886-d204-4ce873386bc1"
      },
      "source": [
        "text_unigrams = [nltk.ngrams(sent, 1) for sent in train]\n",
        "unigrams = []\n",
        "\n",
        "for unigram in text_unigrams: unigrams = unigrams + list(unigram)\n",
        "dist_unigrams = list(set(unigrams))  \n",
        "  \n",
        "print(dist_unigrams[0:10])\n",
        "\n",
        "Fdist_unigram = nltk.probability.FreqDist(unigrams)\n",
        "MLEdist_unigram = nltk.probability.MLEProbDist(Fdist_unigram)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('raised',), ('cast',), ('survivor',), ('chanced',), ('creditable',), ('sides',), ('kindred',), ('ebony',), ('delusion',), ('self-approbation',)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-6hG-jLRTXk",
        "colab_type": "text"
      },
      "source": [
        "##MLEdist_bigram Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3MZFu_IIUdd",
        "colab_type": "code",
        "outputId": "bd2421d5-54c6-4fde-868e-893e69a43fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text_bigrams = [nltk.ngrams(sent, 2) for sent in train]\n",
        "bigrams = []\n",
        "\n",
        "for bigram in text_bigrams: bigrams = bigrams + list(bigram)\n",
        "dist_bigrams = list(set(bigrams))  \n",
        "  \n",
        "print(dist_bigrams[0:10])\n",
        "\n",
        "Fdist_bigram = nltk.probability.FreqDist(bigrams)\n",
        "MLEdist_bigram = nltk.probability.MLEProbDist(Fdist_bigram)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('such', 'denial'), ('following', 'Pages'), ('than', 'ever'), ('cousin', 'Edmund'), ('ordered', 'a'), ('Emma', 'persevered'), ('Bertram', 'nor'), ('exact', 'steps'), ('other', 'night'), ('discovers', 'Popgun')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4UDC2AvRRqg",
        "colab_type": "text"
      },
      "source": [
        "##MLEdist_trigram Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAgqFZYPIU3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0fc80071-9975-492f-df1a-c6a4d8b61ac1"
      },
      "source": [
        "text_trigrams = [nltk.ngrams(sent, 3) for sent in train]\n",
        "trigrams = []\n",
        "\n",
        "for trigram in text_trigrams: trigrams = trigrams + list(trigram)\n",
        "dist_trigrams = list(set(trigrams))  \n",
        "  \n",
        "print(dist_trigrams[0:10])\n",
        "\n",
        "Fdist_trigram = nltk.probability.FreqDist(trigrams)\n",
        "MLEdist_trigram = nltk.probability.MLEProbDist(Fdist_trigram)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('desire', 'of', 'seeing'), ('her', 'from', 'Portsmouth'), ('privileges', 'to', 'be'), ('dear', 'I', 'should'), ('that', 'way', 'most'), ('of', 'little', 'consequence'), ('the', 'same', 'thing'), ('She', 'was', 'willing'), ('often', 'wrong', '.'), ('dangerous', 'precedent', 'indeed')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxt3WVbrRazm",
        "colab_type": "text"
      },
      "source": [
        "##MLEdist_quadgram Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fofPv28cslTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_quadgrams = [nltk.ngrams(sent, 4) for sent in train]\n",
        "quadgrams = []\n",
        "\n",
        "for quadgram in text_quadgrams: quadgrams = quadgrams + list(quadgram)\n",
        "dist_quadgrams = list(set(quadgrams))\n",
        "\n",
        "print(dist_quadgrams[0:10])\n",
        "\n",
        "Fdist_quadgram = nltk.probability.FreqDist(quadgrams)\n",
        "MLEdist_quadgram = nltk.probability.MLEProbDist(Fdist_quadgram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Hf0OBMRfJM",
        "colab_type": "text"
      },
      "source": [
        "##Generators Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S7i-iOdDyZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator_unigram() :\n",
        "  sum_MLE = 0.0\n",
        "  norm_MLE_list = list()\n",
        "  norm_MLE_word = list()\n",
        "  \n",
        "  for k,v in Fdist_unigram.items():\n",
        "    sum_MLE = sum_MLE+ MLEdist_unigram.prob(k)\n",
        "  for k,v in Fdist_unigram.items():\n",
        "    norm_MLE_list.append(MLEdist_unigram.prob(k)/sum_MLE)\n",
        "    norm_MLE_word.append(k)\n",
        "  \n",
        "  index = np.where(np.random.multinomial(1, norm_MLE_list, size=1) == 1)\n",
        "  return norm_MLE_word[index[1][0]][0]\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnq8jbPTHk-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator_bigram(start) :\n",
        "  sum_MLE = 0.0\n",
        "  norm_MLE_list = list()\n",
        "  norm_MLE_word = list()\n",
        "  \n",
        "  for k,v in Fdist_bigram.items():\n",
        "    if start == k[0]:\n",
        "      sum_MLE = sum_MLE + MLEdist_bigram.prob(k)\n",
        "  for k,v in Fdist_bigram.items():\n",
        "    if start == k[0]:\n",
        "      norm_MLE_list.append(MLEdist_bigram.prob(k)/sum_MLE)\n",
        "      norm_MLE_word.append(k)\n",
        "     \n",
        "    \n",
        "  index = np.where(np.random.multinomial(1, norm_MLE_list, size=1) == 1)\n",
        "  return norm_MLE_word[index[1][0]][1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VuHvnXlHlMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator_trigram(start1,start2) :\n",
        "    sum_MLE = 0.0\n",
        "    norm_MLE_list = list()\n",
        "    norm_MLE_word = list()\n",
        "    word2 = str()\n",
        "    \n",
        "    for k,v in Fdist_bigram.items():\n",
        "        if start1 == \"<s>\" and start2 ==\"<s>\":\n",
        "            word2 = Generator_bigram(start1)\n",
        "            if start1 == k[0] and word2 == k[1]:\n",
        "                sum_MLE = sum_MLE + MLEdist_trigram.prob(k)\n",
        "        elif start1 == k[0] and start2 == k[1]:\n",
        "            sum_MLE = sum_MLE + MLEdist_trigram.prob(k)\n",
        "    for k,v in Fdist_bigram.items():\n",
        "        if start1 == \"<s>\" and start2 ==\"<s>\":\n",
        "            if start1 == k[0] and word2 == k[1]:\n",
        "                norm_MLE_list.append(MLEdist_trigram.prob(k)/sum_MLE)\n",
        "                norm_MLE_word.append(k)\n",
        "        elif start1 == k[0] and start2 == k[1]:\n",
        "            norm_MLE_list.append(MLEdist_trigram.prob(k)/sum_MLE)\n",
        "            norm_MLE_word.append(k)\n",
        "            \n",
        "    index = np.where(np.random.multinomial(1, norm_MLE_list, size=1) == 1)\n",
        "    return norm_MLE_word[index[1][0]][2]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWXFl8PkHlZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator_quadgram(start1,start2,start3) :\n",
        "    sum_MLE = 0.0\n",
        "    norm_MLE_list = list()\n",
        "    norm_MLE_word = list()\n",
        "    word2 = str()\n",
        "    word3 = str()\n",
        "    \n",
        "    for k,v in Fdist_bigram.items():\n",
        "        if start1 == \"<s>\" and start2 ==\"<s>\" and start3 ==\"<s>\":\n",
        "            word2 = Generator_bigram(start1)\n",
        "            word3 = Generator_trigram(start1,word2)\n",
        "            if start1 == k[0] and word2 == k[1] and word3 == k[2]:\n",
        "                sum_MLE = sum_MLE + MLEdist_quadgram.prob(k)\n",
        "        elif start1 == k[0] and start2 == k[1] and start2 == k[1]:\n",
        "            sum_MLE = sum_MLE + MLEdist_quadgram.prob(k)\n",
        "    for k,v in Fdist_bigram.items():\n",
        "        if start1 == \"<s>\" and start2 ==\"<s>\" and start3 ==\"<s>\":\n",
        "              if start1 == k[0] and word2 == k[1] and word3 == k[2]:\n",
        "                    norm_MLE_list.append(MLEdist_quadgram.prob(k)/sum_MLE)\n",
        "                    norm_MLE_word.append(k)\n",
        "        elif start1 == k[0] and start2 == k[1]:\n",
        "            norm_MLE_list.append(MLEdist_quadgram.prob(k)/sum_MLE)\n",
        "            norm_MLE_word.append(k)\n",
        "    \n",
        "    index = np.where(np.random.multinomial(1, norm_MLE_list, size=1) == 1)\n",
        "    return norm_MLE_word[index[1][0]][2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpOuvhRuRmsL",
        "colab_type": "text"
      },
      "source": [
        "##Random Sentence Generators using Generators Functions\n",
        "Note: trigram and quadgram take very long to compute and hence when using on colab, the block sometimes times-out "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVDQOolq74ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ngram = str()\n",
        "word = \"<s>\"\n",
        "sentence = list()\n",
        "space = \" \"\n",
        "\n",
        "print(\"Chose N-Gram: \")\n",
        "ngram = input()\n",
        "\n",
        "while(word!=\"</s>\"):\n",
        "    sentence.append(word)\n",
        "    if ngram == \"unigram\":\n",
        "        word = Generator_unigram()\n",
        "    elif ngram == \"bigram\":\n",
        "        word = Generator_bigram(sentence[-1])\n",
        "    elif ngram == \"trigram\":\n",
        "        if word==\"<s>\" and len(sentence)==1:\n",
        "            word = Generator_trigram(word,word)\n",
        "        else:\n",
        "            word = Generator_trigram(sentence[-2],sentence[-1])\n",
        "    elif ngram == \"quadgram\":\n",
        "        if word==\"<s>\" and len(sentence)==1:\n",
        "            word = Generator_quadgram(word,word,word)\n",
        "        else:\n",
        "            word = Generator_quadgram(sentence[-3],sentence[-2],sentence[-1])\n",
        "    print(space.join(sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf_afmb8SLw5",
        "colab_type": "text"
      },
      "source": [
        "##Perplexity Function \n",
        "Note: Written strictly as per defination of function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF4YJ2USw-N1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perplexity():\n",
        "    print(\"Input Test Sentence Sequence - Number in Corpus - you Want to test perplexity of\")  \n",
        "    s = int(input())\n",
        "    print(\"Input N-Gram Model you want to use to derive probabilites\")  \n",
        "    ngram = input()\n",
        "    \n",
        "    log_add = 0.0\n",
        "    train_p = list(train[s])\n",
        "    #print(train_p)\n",
        "    \n",
        "    if ngram == \"unigram\":\n",
        "        grams = [nltk.ngrams(train_p, 1)]\n",
        "    elif ngram == \"bigram\":\n",
        "        grams = [nltk.ngrams(train_p, 2)]\n",
        "    elif ngram == \"trigram\":\n",
        "        grams = [nltk.ngrams(train_p, 3)]\n",
        "    elif ngram == \"quadgram\":\n",
        "        grams = [nltk.ngrams(train_p, 4)]\n",
        "        \n",
        "    grams_list = []\n",
        "    \n",
        "    for gram in grams: grams_list = grams_list + list(gram)\n",
        "        \n",
        "    if ngram == \"unigram\":\n",
        "        for k,v in Fdist_unigram.items():\n",
        "            if k in grams_list:\n",
        "                log_add = math.log(MLEdist_unigram.prob(k),2)\n",
        "    elif ngram == \"bigram\":\n",
        "        for k,v in Fdist_bigram.items():\n",
        "            if k in grams_list:\n",
        "                log_add = math.log(MLEdist_bigram.prob(k),2)\n",
        "    elif ngram == \"trigram\":\n",
        "        for k,v in Fdist_trigram.items():\n",
        "            if k in grams_list:\n",
        "                log_add = math.log(MLEdist_trigram.prob(k),2)\n",
        "    elif ngram == \"quadgram\":\n",
        "        for k,v in Fdist_quadgram.items():\n",
        "            if k in grams_list:\n",
        "                log_add = math.log(MLEdist_quadgram.prob(k),2)\n",
        "    \n",
        "    l = log_add/len(train_p)\n",
        "    \n",
        "    ppw = pow(2,-l)\n",
        "    \n",
        "    print(\"Perplexity is: \")\n",
        "    return ppw\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGzvZ-O66VDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(perplexity())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}